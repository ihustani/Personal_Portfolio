{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0a8b253cea124309dc7872a31b41818e",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your https://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5bf1daebc6046ca28c3cdb668b9d000",
     "grade": false,
     "grade_id": "cell-d0ab748b60d85cd3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile(\"host_server_requests.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e7bfb1bab0ea9927c8e6f6fd39415b44",
     "grade": false,
     "grade_id": "cell-244fd5f7c0138b60",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def process_line(line): # Defined process_line() function\n",
    "    line = line.replace(\" \", \"|\") # String replace space character with pipe\n",
    "    line = line.split(\"|\") # String split on pipe\n",
    "    if line[0] == 'HOST': # If the first value is 'HOST':\n",
    "        x = 1 # x is equal to one\n",
    "    else: # Else:\n",
    "        x = 0 # x is equal to zero\n",
    "    row = Row(f1=float(x), f2=float(line[1]), f3=float(line[2]), f4=float(line[3]), f5=float(line[4]), f6=float(line[5]), f7=float(line[6]), f8=float(line[7]), label=float(line[-1])) # Created row object\n",
    "    return row # Returned row object with each label being assigned to its proper value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
       " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
       " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
       " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
       " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
       " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
       " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
       " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
       " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
       " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "requests_rdd.map(process_line).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f5e9811b6a4249e05f0ab6a8e0bf1b0",
     "grade": true,
     "grade_id": "cell-eb7f9c98c6ea4aa7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "78c9aae903456dc64119177e49791c86",
     "grade": false,
     "grade_id": "cell-b3baf345ff984885",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "| f1|     f2|      f3|      f4|      f5|      f6|      f7|      f8|         label|\n",
      "+---+-------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "|1.0| 2.0E-5| 0.80279|-0.09174| 0.04041|-0.22504| -0.0504| 0.58149| 163.877101489|\n",
      "|1.0| 5.0E-5|-0.00454| -0.0211| 0.00174|-0.11684| 0.19182|-0.23745|-105.023368852|\n",
      "|1.0| 1.5E-4|-0.10437| 0.04869| 0.18333|-0.21864| 0.27638|-0.13441|-115.011801582|\n",
      "|1.0|-1.5E-4| 0.27118| 0.14526| 0.06101| 0.13401| 0.06237|-0.74065|-122.623452696|\n",
      "|1.0|-6.0E-5|  0.1413| 0.12084| 0.05452| 0.09272|  0.2534|-0.65331|-117.130523174|\n",
      "|1.0|-8.0E-5|-0.41534|-0.04205|-0.00724|-0.07463| 0.13273| 0.19112|-73.5775668047|\n",
      "|1.0|-8.0E-5|-0.45937|-0.23509|-0.05679| 0.06077|-0.49597|-0.30668| -137.37933148|\n",
      "|0.0| 2.0E-5|-0.23465| 0.07345|-0.07217|-0.19256|-0.14377|-0.15183|-162.804738349|\n",
      "|0.0|-7.0E-5|-0.10321| 0.27467| 0.04058|-0.24541| 0.08631| -0.2979|-212.111291232|\n",
      "|1.0|-7.0E-5|-0.01039|-0.00453|-0.01352|-0.05199| -0.3772|-0.19641|-91.5022329392|\n",
      "+---+-------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create requests_df variable here\n",
    "requests_df = requests_rdd.map(process_line).toDF() # Transformed the requests_rdd RDD into a Spark 2.0 DataFrame using toDF()\n",
    "requests_df.show(10) # Viewed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "682cb7321d3cb083231d3d5cb9a2cdb5",
     "grade": true,
     "grade_id": "cell-c24d71122ae35aeb",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel` and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5cd64475bf2c5f99796bc209e46bb516",
     "grade": false,
     "grade_id": "cell-15727d5a477764c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- f1: double (nullable = true)\n",
      " |-- mlabel: double (nullable = true)\n",
      " |-- semlabel: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the dataframe `summary_df` below\n",
    "mlabel = requests_df.groupBy('f1').agg(fn.avg('label').alias('mlabel')) # Returned aggregated dataframe for the mean of label\n",
    "function = fn.stddev_samp('label')/fn.sqrt(fn.count('label')) # Created function for standard error of the mean\n",
    "semlabel = requests_df.groupBy('f1').agg((function).alias('semlabel')) # Returned aggregated dataframe for the standard error of the mean of label\n",
    "summary_df = mlabel.join(semlabel, on='f1') # Used a join to combine mlabel and semlabel dataframes as summary_df\n",
    "summary_df.printSchema() # Returned dataframe schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| f1|             mlabel|\n",
      "+---+-------------------+\n",
      "|0.0|-29.611753412328916|\n",
      "|1.0|-12.622431936863203|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_df.select('f1', 'mlabel').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4a4b4a6611408a67a45b7d4b671e0bdd",
     "grade": true,
     "grade_id": "cell-fefc94eb4f5a3aab",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919213,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `va` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9b8e718f4d06bf724fb9be5673a5ad75",
     "grade": false,
     "grade_id": "cell-56d045d1b2c78b89",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "va = feature.VectorAssembler(inputCols=['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8'], outputCol='features') # Created VectorAssembler object\n",
    "features_df = va.transform(requests_df) # Created new features_df using va object\n",
    "features_df.printSchema() # Returned dataframe schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+--------+-------+--------+-------+--------+--------------+--------------------+\n",
      "| f1|    f2|      f3|      f4|     f5|      f6|     f7|      f8|         label|            features|\n",
      "+---+------+--------+--------+-------+--------+-------+--------+--------------+--------------------+\n",
      "|1.0|2.0E-5| 0.80279|-0.09174|0.04041|-0.22504|-0.0504| 0.58149| 163.877101489|[1.0,2.0E-5,0.802...|\n",
      "|1.0|5.0E-5|-0.00454| -0.0211|0.00174|-0.11684|0.19182|-0.23745|-105.023368852|[1.0,5.0E-5,-0.00...|\n",
      "|1.0|1.5E-4|-0.10437| 0.04869|0.18333|-0.21864|0.27638|-0.13441|-115.011801582|[1.0,1.5E-4,-0.10...|\n",
      "+---+------+--------+--------+-------+--------+-------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6eb40dd5b5fa05c1023d76f52b65e6a",
     "grade": true,
     "grade_id": "cell-c4cea7728b05e44a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4abee269b07e549d04187eb6bb0ec423",
     "grade": false,
     "grade_id": "cell-73fa24e4562cc788",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "| 163.877101489| 159.06994708337484|\n",
      "|-105.023368852|  -99.5259872232913|\n",
      "|-115.011801582|-109.91382979074446|\n",
      "|-122.623452696|-118.62864861627719|\n",
      "|-117.130523174| -116.8924575166947|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the linear regression estimator below and name it lr_model.\n",
    "# use the model to create the dataframe predictions_df with two columns label and prediction\n",
    "# by transforming the dataframe `features_df` \n",
    "lr_estimator = regression.LinearRegression(featuresCol='features', labelCol='label') # Created LinearRegression estimator object\n",
    "lr_model = lr_estimator.fit(features_df) # Fit the lr_estimator object to the features_df to create lr_model\n",
    "predictions_df = lr_model.transform(features_df) # Applied model to features_df to return predictions_df\n",
    "predictions_df = predictions_df[['label', 'prediction']] # Relabeled column headers\n",
    "predictions_df.show(5) # Viewed dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d8af6b40c23493d110716af602a6779c",
     "grade": true,
     "grade_id": "cell-34b5676f440b3406",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(va), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `rmse_df` that contains the root mean squared error in column `rmse` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe489899f4801290068db0969c83cd00",
     "grade": false,
     "grade_id": "cell-926f142075117a76",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758143015011|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the `rmse_df` dataframe here\n",
    "rmse = fn.sqrt(fn.sum((fn.col('prediction') - fn.col('label'))**2)/fn.count('prediction')) # Created rmse function\n",
    "rmse_df = predictions_df.select(rmse.alias('rmse')) # Applied rmse function to predictions_df, returned as rmse_df\n",
    "rmse_df.show() # Viewed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69d0c1f4cd5cabd3dadb9dcc8b75e1ea",
     "grade": true,
     "grade_id": "cell-8e931520fb661fef",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_array_less(rmse_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse_df.count(), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
