{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "municipal-guatemala",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a8b253cea124309dc7872a31b41818e",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your https://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fiscal-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature, regression, Pipeline, pipeline, evaluation, tuning, clustering\n",
    "from pyspark.sql import types, Row, functions as fn\n",
    "from pyspark import sql\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-steel",
   "metadata": {},
   "source": [
    "# Part 2: Feature engineering and recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-bundle",
   "metadata": {},
   "source": [
    "In this project, we are going to study a dataset of Spotify songs for which we have a number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-beatles",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3256f5c995b855ba7c4b341b0a9426bd",
     "grade": false,
     "grade_id": "cell-a3d100eed4c0180b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spotify = spark.read.csv('spotify_songs.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "typical-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mask Off</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redbone</td>\n",
       "      <td>Childish Gambino</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xanny Family</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master Of None</td>\n",
       "      <td>Beach House</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.494</td>\n",
       "      <td>199413</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>-15.236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>86.468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parallel Lines</td>\n",
       "      <td>Junior Boys</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.678</td>\n",
       "      <td>392893</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-11.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>174.004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song_title            artist  acousticness  danceability  duration_ms  \\\n",
       "0        Mask Off            Future        0.0102         0.833       204600   \n",
       "1         Redbone  Childish Gambino        0.1990         0.743       326933   \n",
       "2    Xanny Family            Future        0.0344         0.838       185707   \n",
       "3  Master Of None       Beach House        0.6040         0.494       199413   \n",
       "4  Parallel Lines       Junior Boys        0.1800         0.678       392893   \n",
       "\n",
       "   energy  instrumentalness  key  liveness  loudness  mode  speechiness  \\\n",
       "0   0.434          0.021900    2    0.1650    -8.795     1       0.4310   \n",
       "1   0.359          0.006110    1    0.1370   -10.401     1       0.0794   \n",
       "2   0.412          0.000234    2    0.1590    -7.148     1       0.2890   \n",
       "3   0.338          0.510000    5    0.0922   -15.236     1       0.0261   \n",
       "4   0.561          0.512000    5    0.4390   -11.648     0       0.0694   \n",
       "\n",
       "     tempo  time_signature  valence  \n",
       "0  150.062             4.0    0.286  \n",
       "1  160.083             4.0    0.588  \n",
       "2   75.044             4.0    0.173  \n",
       "3   86.468             4.0    0.230  \n",
       "4  174.004             4.0    0.904  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-samoa",
   "metadata": {},
   "source": [
    "## Question 1. (10 pts)\n",
    "First, we will try to understand how the duration, tempo, and key are related to danceability. Unfortunately, each of these features is in different scales, and the feature key is categorical.\n",
    "\n",
    "Create a pipeline called `featurize` that performs the following feature engineering steps\n",
    "- Standardizes and `duration_ms` and `tempo` (you have to combine `feature.VectorAssembler` with `feature.StandardScaler`)\n",
    "- Create dummy variables for `key` (you have to use `feature.OneHotEncoder`. This encoder uses the *last category* as the baseline. Be careful when interpreting it)\n",
    "\n",
    "You have to create a last step in this featurizer that combines the two kinds of engineered features into a column called `features` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innovative-christianity",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50c326766af70da4d7275d69026ccc74",
     "grade": false,
     "grade_id": "cell-fc7d6ee4615ba773",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline to produce principal components of data\n",
    "va1 = feature.VectorAssembler(inputCols=['duration_ms','tempo'], outputCol='initial_features') # Created first VectorAssembler pipeline stage for converting duration_ms and tempo features to a single initial_features vector\n",
    "ss = feature.StandardScaler(withMean=True, inputCol='initial_features', outputCol='scaledFeatures') # Created StandardScaler pipeline stage for standarizing the initial_features vector, output as scaledFeatures\n",
    "dum = feature.OneHotEncoder(inputCol='key', outputCol='key_vector') # Created OneHotEncoder pipeline stage for creating dummy columns for the key column, output as key_vector\n",
    "va2 = feature.VectorAssembler(inputCols=['scaledFeatures','key_vector'], outputCol='features') # Created second VectorAssembler pipeline stage for converting scaled_features and key_vector to a single features vector\n",
    "pipe1 = Pipeline(stages=[va1, ss, dum, va2]) # Created pipeline estimator with va1, ss, dum, and va2 stages\n",
    "featurize = pipe1.fit(spotify) # Fit pipeline to spotify dataset, assigned to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fewer-intelligence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50704547,  1.06628469,  0.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the featurizer here\n",
    "featurize.transform(spotify).select('features').first().features.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "third-assumption",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f27ecd1cde35df50b7ce1903a01cc194",
     "grade": true,
     "grade_id": "cell-b2314cd3e1df9f8c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert type(featurize) == pipeline.PipelineModel\n",
    "assert feature.StandardScalerModel in list(map(type, featurize.stages))\n",
    "assert feature.OneHotEncoderModel in list(map(type, featurize.stages))\n",
    "assert feature.VectorAssembler in list(map(type, featurize.stages))\n",
    "assert len(featurize.transform(spotify).select('features').first().features.toArray()) == 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-campaign",
   "metadata": {},
   "source": [
    "## Question 2: (15 pts)\n",
    "We will now compare a model without feature engineering to one with feature engineering.\n",
    "\n",
    "First, create a vanilla pipeline that takes `duration`, `tempo`, and `key` without any feature engineering and assembles them into a column `features`. Call this pipeline `vanilla_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italic-internet",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14928b99972399ffdf3880d826533b10",
     "grade": false,
     "grade_id": "cell-f34d0f48df586706",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline for vanilla featurizer\n",
    "va = feature.VectorAssembler(inputCols=['duration_ms', 'tempo', 'key'], outputCol='features') # Created VectorAssembler pipeline stage for converting duration_ms, tempo, and key features to a single features vector\n",
    "pipe2 = Pipeline(stages=[va]) # Created pipeline estimator with va stage\n",
    "vanilla_features = pipe2.fit(spotify) # Fit pipeline to spotify dataset, assigned to vanilla_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alpha-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.04600e+05, 1.50062e+02, 2.00000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your pipeline\n",
    "vanilla_features.transform(spotify).first().features.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "silver-jamaica",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5630e8813c0e4e13d2868896b6e0a45d",
     "grade": true,
     "grade_id": "cell-8f3f865be20d6d07",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "assert type(vanilla_features) == pipeline.PipelineModel\n",
    "assert len(vanilla_features.transform(spotify).select('features').first().features.toArray()) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-warner",
   "metadata": {},
   "source": [
    "Now, create two regression pipeline estimators (don't fit them) `model_fe` and `model_vanilla` where `model_fe` uses the featurizer from Question 1 to create the features and `model_vanilla` creates the features using the previous pipeline. Remember that you are predicting `danceability`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "injured-stations",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aafc543490b92a5d6f0f5fadc4739c33",
     "grade": false,
     "grade_id": "cell-567bc2f06def8269",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline for models\n",
    "lr = regression.LinearRegression(featuresCol='features', labelCol='danceability') # Created LinearRegression pipeline to fit a regression between the features and danceability label column\n",
    "model1 = Pipeline(stages=[pipe1, lr]) # Created pipeline estimator using the first pipeline and the lr stage, assigned to model1 (model_fe)\n",
    "model2 = Pipeline(stages=[pipe2, lr]) # Created pipeline estimator using the second pipeline and the lr stage, assigned to model2 (model_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "equal-appeal",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c212595b4d212c5c633204fceee8c8d1",
     "grade": true,
     "grade_id": "cell-b309ca11d308d35f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "assert type(model1) == pipeline.Pipeline\n",
    "assert len(model1.getStages()) == 2\n",
    "assert type(model2) == pipeline.Pipeline\n",
    "assert len(model2.getStages()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-novelty",
   "metadata": {},
   "source": [
    "With the code below, we will evaluate the performance of each of the models and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "injured-classroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE model 1:  0.1606288932465125\n",
      "RMSE model 2:  0.1609551207566255\n"
     ]
    }
   ],
   "source": [
    "regression_evaluator = evaluation.RegressionEvaluator(labelCol='danceability', metricName='rmse')\n",
    "training_df, validation_df = spotify.randomSplit([0.8, 0.2], seed=0)\n",
    "\n",
    "print(\"RMSE model 1: \", regression_evaluator.evaluate(model1.fit(training_df).transform(validation_df)))\n",
    "print(\"RMSE model 2: \", regression_evaluator.evaluate(model2.fit(training_df).transform(validation_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-function",
   "metadata": {},
   "source": [
    "**(5 pts)** Based on the results above, what can you say about the model with feature engineering. Is there are big difference in performance? If not, why would it be worth doing feature engineering anyway? Answer below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-rapid",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5e67264d2b3b2b55dd06d05097e98c0",
     "grade": true,
     "grade_id": "cell-e0b6d5e1cc91f239",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "There is a slight improvement in performance for the model with feature engineering vs. the model without feature engineering. Even though there was not a big difference in performance, it is still worth doing feature engineering anyway for several reasons. Feature engineering can help algorithms converge faster, find better fits to the training data, find more generalizable solutions, and find more interpretable solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-foundation",
   "metadata": {},
   "source": [
    "## Question 3: (25 pts) Clustering\n",
    "\n",
    "We will now make recommendation of songs based on k-means. Create a pipeline where you fit a 10-cluster KMeans to the following features **after standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "early-violin",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cab49be872531431a1b62e5a016af39",
     "grade": false,
     "grade_id": "cell-891657c21c2e4e7b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "feature_list = ['acousticness',\n",
    " 'danceability',\n",
    " 'duration_ms',\n",
    " 'energy',\n",
    " 'instrumentalness',\n",
    " 'key',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'tempo',\n",
    " 'time_signature',\n",
    " 'valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-understanding",
   "metadata": {},
   "source": [
    "Name the pipeline `spotify_clustering` and make sure that the `KMeans` model has a prediction column called `cluster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twelve-amino",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0dd885a2340d06427964dd015d46107",
     "grade": false,
     "grade_id": "cell-20dba717da0f0efa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline spotify_clustering\n",
    "va = feature.VectorAssembler(inputCols=feature_list, outputCol='features') # Created VectorAssembler pipeline stage for converting features in feature_list to a single features vector\n",
    "ss = feature.StandardScaler(withMean=True, inputCol='features', outputCol='scaledFeatures') # Created StandardScaler pipeline stage for standarizing the features vector, output as scaledFeatures\n",
    "km = clustering.KMeans(k = 10, featuresCol='scaledFeatures', predictionCol='cluster') # Created KMeans pipeline stage where k = 10 from the scaledfeatures column, with each prediction cluster output to a predictions column\n",
    "pipe3 = Pipeline(stages=[va, ss, km]) # Created pipeline estimator with va, ss, and km stages\n",
    "spotify_clustering = pipe3.fit(spotify) # Fit pipeline to spotify dataset, assigned to spotify_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "auburn-memory",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18768d7de3b91c38df3b776a70372512",
     "grade": true,
     "grade_id": "cell-f38f573e553928b6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert type(spotify_clustering) == pipeline.PipelineModel\n",
    "assert feature.StandardScalerModel in set(map(type, spotify_clustering.stages))\n",
    "assert spotify_clustering.stages[-1].extractParamMap()[(spotify_clustering.stages[-1].k)] == 10\n",
    "assert spotify_clustering.stages[-1].extractParamMap()[(spotify_clustering.stages[-1].predictionCol)] == 'cluster'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-valentine",
   "metadata": {},
   "source": [
    "As you all know, the professor is a big fan of Meat Loaf (the artists, obviously) and his song \"I will do anything for love (But I won't do that)\" because it is close to the professor's mantra: \"I will do anything for data (But I won't overfit)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "objective-completion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd Do Anything For Love (But I Won't Do That)\n"
     ]
    }
   ],
   "source": [
    "meat_loaf = spotify.where(fn.col('artist') == \"Meat Loaf\")\n",
    "print(meat_loaf.first().song_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-andorra",
   "metadata": {},
   "source": [
    "In the cell below, extract the cluster number of Meat Loaf's song and store it in `meat_loaf_cluster_id`. Also, create a Spark DataFrame `similar_songs` with the songs from that Meat Loaf's cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "still-testing",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0466b5e9939310027a4f1872d11733",
     "grade": false,
     "grade_id": "cell-061eec47df5a532f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Title: I'd Do Anything For Love (But I Won't Do That)\n",
      "Song Cluster: 8\n"
     ]
    }
   ],
   "source": [
    "# create variable meat_loaf_cluster_id and dataframe similar_songs\n",
    "clustered = spotify_clustering.transform(spotify) # Returned transformed dataframe using spotify_clustering pipeline\n",
    "meat_loaf2 = clustered.where(fn.col('artist') == \"Meat Loaf\") # Created dataframe with songs by the artist Meat Loaf\n",
    "print(f'Song Title: {meat_loaf2.first().song_title}') # Confirmed the title of the first song in the meat_loaf2 dataframe\n",
    "meat_loaf_cluster_id = meat_loaf2.first().cluster # Extracted the cluster number of Meat Loaf's song\n",
    "print(f'Song Cluster: {meat_loaf_cluster_id}') # Confirmed the cluster of the first song in the meat_loaf2 dataframe\n",
    "similar_songs = clustered.where(fn.col('cluster') == meat_loaf_cluster_id) # Created similar_songs dataframe with the songs from that Meat Loaf's song cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "available-magic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redbone</td>\n",
       "      <td>Childish Gambino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Master Of None</td>\n",
       "      <td>Beach House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cemalim</td>\n",
       "      <td>Erkin Koray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One Night</td>\n",
       "      <td>Lil Yachty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please Stop Making Fake Versace</td>\n",
       "      <td>Father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coming Home</td>\n",
       "      <td>Leon Bridges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L$D</td>\n",
       "      <td>A$AP Rocky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baby</td>\n",
       "      <td>Ariel Pink's Haunted Graffiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sabali</td>\n",
       "      <td>Amadou &amp; Mariam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Them Changes (feat. Flying Lotus &amp; Kamasi Wash...</td>\n",
       "      <td>Thundercat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          song_title  \\\n",
       "0                                            Redbone   \n",
       "1                                     Master Of None   \n",
       "2                                            Cemalim   \n",
       "3                                          One Night   \n",
       "4                    Please Stop Making Fake Versace   \n",
       "5                                        Coming Home   \n",
       "6                                                L$D   \n",
       "7                                               Baby   \n",
       "8                                             Sabali   \n",
       "9  Them Changes (feat. Flying Lotus & Kamasi Wash...   \n",
       "\n",
       "                          artist  \n",
       "0               Childish Gambino  \n",
       "1                    Beach House  \n",
       "2                    Erkin Koray  \n",
       "3                     Lil Yachty  \n",
       "4                         Father  \n",
       "5                   Leon Bridges  \n",
       "6                     A$AP Rocky  \n",
       "7  Ariel Pink's Haunted Graffiti  \n",
       "8                Amadou & Mariam  \n",
       "9                     Thundercat  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the following code to find suggestions\n",
    "similar_songs.select('song_title', 'artist').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "greek-horizon",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a97a79772c55aa504eaf41cd968dff3f",
     "grade": true,
     "grade_id": "cell-83e735291aaacb75",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert 0 <= meat_loaf_cluster_id <= 9\n",
    "assert similar_songs.count() < spotify.count()\n",
    "assert similar_songs.where('cluster == 0')\n",
    "assert similar_songs.where('cluster = ' + str(meat_loaf_cluster_id)).where('artist = \"Meat Loaf\"').count() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-rating",
   "metadata": {},
   "source": [
    "One of the problems wih `KMeans` is that clusters are sometimes unbalanced. Analyze the clustering by creating a dataframe `cluster_analysis` where the first column is the cluster (`cluster`) and the second is the number of song for such cluster (`n_songs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "developing-graduation",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89682022d1d3177d29b6c2a17998353",
     "grade": false,
     "grade_id": "cell-da84475ea6bfb18b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|cluster|n_songs|\n",
      "+-------+-------+\n",
      "|      1|    275|\n",
      "|      6|    365|\n",
      "|      3|     72|\n",
      "|      5|    321|\n",
      "|      9|     83|\n",
      "|      4|    144|\n",
      "|      8|    176|\n",
      "|      7|    226|\n",
      "|      2|    176|\n",
      "|      0|    171|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe cluster_analysis\n",
    "cluster_analysis = clustered.groupby('cluster').count() # Created dataframe with the count of each cluster using the groupby() function\n",
    "cluster_analysis = cluster_analysis.withColumnRenamed('count','n_songs') # Renamed the count column to n_songs\n",
    "cluster_analysis.show() # Viewed resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unexpected-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "(cluster_analysis\n",
    " .toPandas()\n",
    " .sort_values('n_songs', ascending=False)\n",
    " .reset_index()\n",
    " .n_songs.plot(y='n_songs', kind='bar')\n",
    ");\n",
    "plt.xlabel('cluster rank')\n",
    "plt.ylabel('# songs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "speaking-subcommittee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de0b836e673e43f4039869d443a622f",
     "grade": true,
     "grade_id": "cell-b44b2a79f3452fd4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "assert cluster_analysis.count() == 10\n",
    "assert type(cluster_analysis) == sql.dataframe.DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
