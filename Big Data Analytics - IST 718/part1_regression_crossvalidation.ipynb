{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Servo analysis\n",
    "\n",
    "In this assignment, you will continue the analysis we started in class of the Servo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Servo data analysis\n",
    "\n",
    "```console\n",
    "1. Title: Servo Data\n",
    "\n",
    "2. Sources\n",
    "   (a) Created by: Karl Ulrich (MIT) in 1986\n",
    "   (b) Donor: Ross Quinlan\n",
    "   (c) Date: May 1993\n",
    "\n",
    "3. Past Usage:\n",
    "\n",
    "   1.  Quinlan, J.R., \"Learning with continuous classes\", Proc. 5th Australian\n",
    "       Joint Conference on AI (eds A. Adams and L. Sterling), Singapore: World\n",
    "       Scientific, 1992\n",
    " \n",
    "   2.  Quinlan, J.R., \"Combining instance-based and model-based learning\",\n",
    "       Proc. ML'93 (ed P.E. Utgoff), San Mateo: Morgan Kaufmann 1993\n",
    " \n",
    "       Results on 10-way cross-validation:\n",
    " \n",
    "       Method\t\t\tAverage\t\tRelative\n",
    "       ------\t\t\t |Err|\t\t Error\n",
    " \t\t\t\t-------\t\t--------\n",
    " \n",
    "       Guessing mean\t\t  1.15\t\t  1.00\n",
    "       Instance-based\t\t   .52\t\t   .26\n",
    "       Regression\t\t   .86\t\t   .49\n",
    "       Model trees\t\t   .45\t\t   .29\n",
    "       Neural nets (G. Hinton)\t   .30\t\t   .11\n",
    "       Regression+instances\t   .48\t\t   .20\n",
    "       Model trees+instances\t   .30\t\t   .17\n",
    "       NN+instances\t\t   .29\t\t   .11\n",
    " \n",
    "4. Relevant Information:\n",
    "\n",
    "   Ross Quinlan:\n",
    "\n",
    "   This data was given to me by Karl Ulrich at MIT in 1986.  I didn't \n",
    "   record his description at the time, but here's his subsequent (1992) \n",
    "   recollection:\n",
    " \n",
    "     \"I seem to remember that the data was from a simulation of a servo\n",
    "     system involving a servo amplifier, a motor, a lead screw/nut, and a\n",
    "     sliding carriage of some sort.  It may have been on of the\n",
    "     translational axes of a robot on the 9th floor of the AI lab.  In any\n",
    "     case, the output value is almost certainly a rise time, or the time\n",
    "     required for the system to respond to a step change in a position set\n",
    "     point.\"\n",
    " \n",
    "   (Quinlan, ML'93)\n",
    "\n",
    "   \"This is an interesting collection of data provided by Karl \n",
    "    Ulrich.  It covers an extremely non-linear phenomenon - predicting the \n",
    "    rise time of a servomechanism in terms of two (continuous) gain settings\n",
    "    and two (discrete) choices of mechanical linkages.\"\n",
    "\n",
    "5. Number of Instances: 167\n",
    "\n",
    "6. Number of Attributes: 4 + numeric class attribute\n",
    "\n",
    "7. Attribute information:\n",
    "\n",
    "   1. motor: A,B,C,D,E\n",
    "   2. screw: A,B,C,D,E\n",
    "   3. pgain: 3,4,5,6\n",
    "   4. vgain: 1,2,3,4,5\n",
    "   5. class: 0.13 to 7.10\n",
    "\n",
    "8. Missing Attribute Values: None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "servo_df = spark.createDataFrame(pd.read_csv('servo.data',\n",
    "            sep=',', \n",
    "            header=None,\n",
    "            names=['motor', 'screw', 'pgain', 'vgain', 'rise_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With big data, datasets can be too big to bring them into the Spark client. However, we can use the `limit` method of a dataframe to limit the number of rows to bring as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe `servo_sample_df` with the first 20 rows of `servo_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "451a05ca5f0fd8171dacfea14ac9ba5f",
     "grade": false,
     "grade_id": "cell-c9d521c675b461ab",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create `servo_sample_df`\n",
    "servo_sample_df = servo_df.limit(20) # Created servo_sample_df using the first 20 rows of servo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "43a81391a0c03b713650167c51d422a8",
     "grade": true,
     "grade_id": "cell-945bf936abee733a",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 2 pts - right number of rows\n",
    "np.testing.assert_equal(servo_sample_df.count(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 pts)** Below, transform `servo_sample_df` into a Pandas dataframe and do a scatter plot of `motor` vs `rise_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9d391fad8156223a222178d6b656f6dc",
     "grade": true,
     "grade_id": "cell-1df4f53b56e45b6e",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "servo_sample_df.toPandas().plot(x='motor', y='rise_time', kind='scatter'); # Created scatter plot of motor vs rise_time using converted pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 pts)** Below, transform `servo_sample_df` into a Pandas dataframe and do a scatter plot of `screw` vs `rise_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fba3bc6e5a7085effcbedb3f55e6ac55",
     "grade": true,
     "grade_id": "cell-35b7ad7b19c37628",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "servo_sample_df.toPandas().plot(x='screw', y='rise_time', kind='scatter'); # Created scatter plot of screw vs rise_time using converted pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform correlations between vgain-rise time, pgain-rise time, and vgain-pgain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `servo_corr_df` dataframe that contains the correlations between `vgain` and `rise_time` as a column `corr_vgain_rise_time`, between `pgain` and `rise_time` as `corr_pgain_rise_time`, and `vgain` and `pgain` as `corr_vgain_pgain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d63807a257294b716b517f2cc48dea12",
     "grade": false,
     "grade_id": "cell-f59db3726a6aa941",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|corr_vgain_rise_time|corr_pgain_rise_time|  corr_vgain_pgain|\n",
      "+--------------------+--------------------+------------------+\n",
      "|-0.36438266626914595| -0.5981287119612234|0.8122683058183874|\n",
      "+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create `servo_corr_df` here\n",
    "servo_corr_df = servo_df.select(fn.corr('vgain', 'rise_time').alias('corr_vgain_rise_time'), fn.corr('pgain', 'rise_time').alias('corr_pgain_rise_time'), fn.corr('vgain', 'pgain').alias('corr_vgain_pgain')) # Created servo_corr_df dataframe using correlations between vgain and rise_time, pgain and rise_time, and vgain and pgain\n",
    "servo_corr_df.show() # Viewed resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "63043687d2890640bf59ccf9fcabe580",
     "grade": true,
     "grade_id": "cell-fe722ee58305de94",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## 7 pts\n",
    "np.testing.assert_equal(set(servo_corr_df.columns), \n",
    "                        {'corr_pgain_rise_time', 'corr_vgain_pgain', 'corr_vgain_rise_time'})\n",
    "np.testing.assert_almost_equal(list(servo_corr_df.first().asDict().values()),\n",
    "                               [-0.36438266626914595, -0.5981287119612234, 0.8122683058183874], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute mean rise_time for different motors and screws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `motor_rise_time_df` with the column `motor` and `avg_rise_time`, where `avg_rise_time` is the average rise time for a motor. Sort the resulting dataframe from highest to lowest average rise time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad93ae6ce6e96f87f92ad0cea9481137",
     "grade": false,
     "grade_id": "cell-98ecb41cfdc326a3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|motor|     avg_rise_time|\n",
      "+-----+------------------+\n",
      "|    A| 1.761110668888889|\n",
      "|    B| 1.681942367777778|\n",
      "|    C|     1.25406100675|\n",
      "|    E|1.1448932081818182|\n",
      "|    D|0.9176125145454546|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "motor_rise_time_df = servo_df.groupBy('motor').agg(fn.avg('rise_time').alias('avg_rise_time')) # Created motor_rise_time_df computing average rise time for each motor using the groupBy() function\n",
    "motor_rise_time_df = motor_rise_time_df.orderBy('avg_rise_time', ascending=False) # Ordered motor_rise_time_df by average rise time descending\n",
    "motor_rise_time_df.show() # Viewed resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4b3fcf37c16d39a9b3a85cec05508553",
     "grade": true,
     "grade_id": "cell-a3fd7964078508ad",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (motor_rise_time_df.orderBy('motor').select('avg_rise_time').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect())\n",
    "    ,\n",
    "[[1.761110668888889],\n",
    " [1.6819423677777776],\n",
    " [1.2540610067499998],\n",
    " [0.9176125145454546],\n",
    " [1.144893208181818]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `screw_rise_time_df` with the column `screw` and `avg_rise_time` sorted from highest to lowest average rise time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b2a40fc0219dc6b18a898e6b8557110c",
     "grade": false,
     "grade_id": "cell-8ace067a04ebf09a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|screw|     avg_rise_time|\n",
      "+-----+------------------+\n",
      "|    A|1.7684612121428573|\n",
      "|    B|1.3919625091428571|\n",
      "|    C|1.2485862280645164|\n",
      "|    E|1.2256432917241378|\n",
      "|    D|1.1612471173333332|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "screw_rise_time_df = servo_df.groupBy('screw').agg(fn.avg('rise_time').alias('avg_rise_time')) # Created screw_rise_time_df computing average rise time for each screw using the groupBy() function\n",
    "screw_rise_time_df = screw_rise_time_df.orderBy('avg_rise_time', ascending=False) # Ordered screw_rise_time_df by average rise time descending\n",
    "screw_rise_time_df.show() # Viewed resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f99769bb3e1453e45c9257acb8a0f38c",
     "grade": true,
     "grade_id": "cell-e72d1676e16b246b",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (screw_rise_time_df.orderBy('screw').select('avg_rise_time').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect())\n",
    "    ,\n",
    "       [[1.768461212142857],\n",
    " [1.3919625091428571],\n",
    " [1.2485862280645161],\n",
    " [1.1612471173333332],\n",
    " [1.225643291724138]],\n",
    "decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables for motors and screws\n",
    "Create a dataframe `dummy_df` with columns `motor` and `screw` as dummy variables, and columns `vgain`, `pgain`, and `rise_time`. Use motor D and screw C as the baselines and name the dummy variables `motor_A` for motor `A` and so on. Follow a similar pattern for screw. The dataframe `dummy_df` should not contain the columns `motor` and `screw` but only their dummy variable representations. **All column types should be float or integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "50bd1d331eeeeecabad0c2c873438372",
     "grade": false,
     "grade_id": "cell-eb211f716041febd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|vgain|pgain| rise_time|motor_A|motor_B|motor_C|motor_E|screw_A|screw_B|screw_D|screw_E|\n",
      "+-----+-----+----------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|    4|    5|0.28125095|      0|      0|      0|      1|      0|      0|      0|      1|\n",
      "|    5|    6| 0.5062525|      0|      1|      0|      0|      0|      0|      1|      0|\n",
      "|    3|    4|0.35625148|      0|      0|      0|      0|      0|      0|      1|      0|\n",
      "|    2|    3|  5.500033|      0|      1|      0|      0|      1|      0|      0|      0|\n",
      "|    5|    6|0.35625148|      0|      0|      0|      0|      0|      1|      0|      0|\n",
      "|    3|    4| 0.8062546|      0|      0|      0|      1|      0|      0|      0|      0|\n",
      "|    2|    3|  5.100014|      0|      0|      1|      0|      1|      0|      0|      0|\n",
      "|    2|    3| 5.7000422|      1|      0|      0|      0|      1|      0|      0|      0|\n",
      "|    5|    6|0.76875436|      0|      0|      1|      0|      1|      0|      0|      0|\n",
      "|    1|    4| 1.0312537|      0|      0|      0|      0|      1|      0|      0|      0|\n",
      "|    5|    6|0.46875226|      0|      1|      0|      0|      0|      0|      0|      1|\n",
      "|    4|    5|0.39375174|      0|      0|      0|      1|      0|      0|      0|      0|\n",
      "|    1|    4|0.28125095|      0|      1|      0|      0|      0|      0|      0|      0|\n",
      "|    1|    3|       1.1|      0|      0|      0|      1|      0|      0|      0|      0|\n",
      "|    4|    5| 0.5062525|      0|      0|      1|      0|      0|      0|      0|      0|\n",
      "|    2|    3| 1.8999897|      0|      0|      0|      1|      0|      1|      0|      0|\n",
      "|    1|    3| 0.9000011|      0|      0|      0|      0|      0|      0|      0|      0|\n",
      "|    4|    5|0.46875226|      0|      1|      0|      0|      0|      0|      0|      0|\n",
      "|    4|    5| 0.5437528|      0|      1|      0|      0|      0|      1|      0|      0|\n",
      "|    2|    4|0.20625044|      0|      0|      1|      0|      0|      0|      0|      1|\n",
      "+-----+-----+----------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dummy_df below\n",
    "expanded_features = servo_df.select('motor').distinct().rdd.flatMap(lambda x: x).collect() # Returned list of distinct values in the 'motor' column\n",
    "new_features = [fn.when(fn.col('motor') == feature, 1).otherwise(0).alias('motor_'+feature) for feature in expanded_features] # Returned dummy columns for motor features for each item in expanded_features list with motor_D as the baseline\n",
    "\n",
    "dummy_df = servo_df.select(\"vgain\", \"pgain\", \"rise_time\", \"screw\", new_features[0], new_features[1], new_features[2], new_features[3], new_features[4]) # Created new dummy_df including new engineered motor features\n",
    "\n",
    "expanded_features = dummy_df.select('screw').distinct().rdd.flatMap(lambda x: x).collect() # Returned list of distinct values in the 'screw' column\n",
    "new_features = [fn.when(fn.col('screw') == feature, 1).otherwise(0).alias('screw_'+feature) for feature in expanded_features]  # Returned dummy columns for screw features for each item in expanded_features list with screw_C as the baseline\n",
    "\n",
    "dummy_df = dummy_df.select('vgain', 'pgain', 'rise_time', 'motor_A', 'motor_B', 'motor_C', 'motor_E', new_features[0], new_features[1], new_features[2], new_features[3], new_features[4]) # Created new dummy_df including new engineered screw features\n",
    "dummy_df = dummy_df.select('vgain', 'pgain', 'rise_time', 'motor_A', 'motor_B', 'motor_C', 'motor_E', 'screw_A', 'screw_B', 'screw_D', 'screw_E') # Reordered columns\n",
    "dummy_df.show() # Viewed Resulting Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54ee15ea1229510a08e9c1b1acb1a039",
     "grade": true,
     "grade_id": "cell-9fdc091f4ff491bf",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_equal(len(dummy_df.columns), 11)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('motor_A')).first()['sum(motor_A)'], 36)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('screw_A')).first()['sum(screw_A)'], 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison\n",
    "\n",
    "In the next set of questions, you will use the splits below to fit, validate, and estimate the generalization error of your models. The `randomSplit` is called with a seed so that it does not change from what the professor used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "679501d8b3b5eca4b45bb5ce33c85bd2",
     "grade": false,
     "grade_id": "cell-50d140f5bb9fb0a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# points in training:  98\n",
      "# points in validation:  52\n",
      "# points in testing:  17\n"
     ]
    }
   ],
   "source": [
    "training_df, validation_df, testing_df = dummy_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "print(\"# points in training: \", training_df.count())\n",
    "print(\"# points in validation: \", validation_df.count())\n",
    "print(\"# points in testing: \", testing_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose three regression models\n",
    "\n",
    "In the next section, you will choose the best model to explain the data in `servo_df`. Select the right split of the data for the right step of the process (i.e., training, validation, and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Fit model with only `pgain`\n",
    "\n",
    "Create a pipeline that takes *pgain* as a feature to predict *rise time* and fits a linear regression model. You should start your pipeline by taking the appropriate column or columns from `dummy_df` in which the raw feature `pgain` may or may not have been feature engineered. Assign the fit pipeline transformer to `pipe_model1`. Your pipeline must have one vector assembler followed by a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e13dd6486f50f9fdd385d0e435a808b5",
     "grade": false,
     "grade_id": "cell-3b76b5c1134779fc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model1` below\n",
    "va = feature.VectorAssembler(inputCols=['pgain'], outputCol='features') # Created vector assembler stage that takes pgain as the input column and creates features as the output column\n",
    "lr = regression.LinearRegression(featuresCol='features', labelCol='rise_time') # Created linear regression stage that takes features as the input column and creates rise_time as the output column\n",
    "pipe = Pipeline(stages=[va, lr]) # Created pipe with vector assembler and linear regression stages\n",
    "pipe_model1 = pipe.fit(training_df) # Fit pipe to training data to create pipe_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1c239aa677cdd76caa08a036ae4cffd",
     "grade": true,
     "grade_id": "cell-3944466629fee9da",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model1.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Fit model with only `vgain`\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a9befb44f4f0a022cff725205ae67877",
     "grade": false,
     "grade_id": "cell-52aee024a8f17921",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model2` below\n",
    "va = feature.VectorAssembler(inputCols=['vgain'], outputCol='features') # Created vector assembler stage that takes vgain as the input column and creates features as the output column\n",
    "lr = regression.LinearRegression(featuresCol='features', labelCol='rise_time') # Created linear regression stage that takes features as the input column and creates rise_time as the output column\n",
    "pipe = Pipeline(stages=[va, lr]) # Created pipe with vector assembler and linear regression stages\n",
    "pipe_model2 = pipe.fit(training_df) # Fit pipe to training data to create pipe_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4932a21cd41306da5c217705433507f7",
     "grade": true,
     "grade_id": "cell-d278316c89d97741",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model2.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Fit model with only motor, screw, pgain, and vgain\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model3`. Remember that some features have been feature engineered. In particular, use the transformed columns in the order: motor, screw, pgain, and vgain. Choose the columns from `dummy_df` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "35a8633d09ab0c29fd669fee3c06e97a",
     "grade": false,
     "grade_id": "cell-c120f9f58afe1ee6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model3` below\n",
    "va = feature.VectorAssembler(inputCols=['motor_A', 'motor_B', 'motor_C', 'motor_E', 'screw_A', 'screw_B', 'screw_D', 'screw_E', 'pgain', 'vgain'], outputCol='features') # Created vector assembler stage that takes all motor and screw features along with pgain and vgain as the input columns and creates features as the output column\n",
    "lr = regression.LinearRegression(featuresCol='features', labelCol='rise_time') # Created linear regression stage that takes features as the input column and creates rise_time as the output column\n",
    "pipe = Pipeline(stages=[va, lr]) # Created pipe with vector assembler and linear regression stages\n",
    "pipe_model3 = pipe.fit(training_df) # Fit pipe to training data to create pipe_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "64c5a8082b38841e089079c4fde91727",
     "grade": true,
     "grade_id": "cell-1cfd038a4f349405",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model3.stages[1].coefficients.shape, (10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate RMSE on validation data for the three models\n",
    "\n",
    "Create three dataframes `rmse1_df`, `rmse2_df`, and `rmse3_df` for models 1, 2, and 3, respectively, with only with column `rmse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dc5e62f02884fcce8ae909945800700f",
     "grade": false,
     "grade_id": "cell-a9dc54b0e8d696ef",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rmse1_df, rmse2_df, and rmse3_df dataframes below\n",
    "rmse = fn.sqrt(fn.sum((fn.col('prediction') - fn.col('rise_time'))**2)/fn.count('prediction')) # Created rmse function\n",
    "rmse1_df = pipe_model1.transform(validation_df).select(rmse.alias('rmse')) # Estimated rmse for pipe_model1 using predefined rmse function\n",
    "rmse2_df = pipe_model2.transform(validation_df).select(rmse.alias('rmse')) # Estimated rmse for pipe_model2 using predefined rmse function\n",
    "rmse3_df = pipe_model3.transform(validation_df).select(rmse.alias('rmse')) # Estimated rmse for pipe_model3 using predefined rmse function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|1.1789938889898768|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|1.4002432387849721|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|1.0571737251522937|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the answers here\n",
    "rmse1_df.show() # Viewed pipe_model1 rmse\n",
    "rmse2_df.show() # Viewed pipe_model2 rmse\n",
    "rmse3_df.show() # Viewed pipe_model3 rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5184ddaec56494171407cfb72d94dd58",
     "grade": true,
     "grade_id": "cell-ef7fe89203dcf7ae",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(rmse1_df.count(), 1)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)\n",
    "np.testing.assert_equal(rmse3_df.count(), 1)\n",
    "np.testing.assert_equal(rmse1_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse2_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse3_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the best cross validated model to a variable `best_model` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3f7ff2f70265cbad1dc39394c737a946",
     "grade": false,
     "grade_id": "cell-ae68c8174768b63e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# assign best model (the best pipeline transformer) to a variable best_model below\n",
    "best_model = pipe_model3 # Assigned pipe_model3 as the best model as it had the lowest rmse in validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6149102c64b5742a9532945cad43daba",
     "grade": true,
     "grade_id": "cell-8d3e6c2fc9feb10f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts)\n",
    "np.testing.assert_equal(type(best_model), pyspark.ml.pipeline.PipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate generalization performance with RMSE\n",
    "\n",
    "Create a variable `rmse_best_df` that contains the RMSE of the best model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "69148aec455c19af6abda44a65d5c6cf",
     "grade": false,
     "grade_id": "cell-be77e90562322046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rmse_best_df\n",
    "rmse_best_df = best_model.transform(testing_df).select(rmse.alias('rmse')) # Computed the rmse for the best_model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a496ead0654ee61fcfa6802586301e9",
     "grade": true,
     "grade_id": "cell-7ea33e8409261269",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (3 pts)\n",
    "np.testing.assert_equal(rmse_best_df.count(), 1)\n",
    "np.testing.assert_equal(rmse_best_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 pts)** What is the best estimated generalization performance of the best model? Answer in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87ceb0a1ca6b81effacaacd94574af69",
     "grade": true,
     "grade_id": "cell-250e44de7b4539f3",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|1.1373137742756037|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmse_best_df.show() # Viewed best estimated generalization performance of the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that model 3 is the best one. Redefine a new pipeline for this model called `pipe_model_best` and fit it to the **entire training data** (all of `dummy_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7414f608465227abb4a64b9657bb0f72",
     "grade": false,
     "grade_id": "cell-5d347fc67e4a77b6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model_best` below\n",
    "va = feature.VectorAssembler(inputCols=['motor_A', 'motor_B', 'motor_C', 'motor_E', 'screw_A', 'screw_B', 'screw_D', 'screw_E', 'pgain', 'vgain'], outputCol='features') # Created vector assembler stage that takes all motor and screw features along with pgain and vgain as the input columns and creates features as the output column\n",
    "lr = regression.LinearRegression(featuresCol='features', labelCol='rise_time') # Created linear regression stage that takes features as the input column and creates rise_time as the output column\n",
    "pipe = Pipeline(stages=[va, lr]) # Created pipe with vector assembler and linear regression stages\n",
    "pipe_model_best = pipe.fit(dummy_df) # Fit pipe to training data to create pipe_model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "309d7279ebeea7fa95af4c654858d50f",
     "grade": true,
     "grade_id": "cell-230c8b35da808e47",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (4 pts) check that the model was fitted correctly\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model_best.stages[1].coefficients.shape, (10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4 pts)** Assume that all features on `dummy_df` were comparable (i.e., standardized). Taking motor D and screw C as the baseline, what are the top 2 most important features for *increasing rise time* and the top 2 most important features for *decreasing rise time*? Answer below with code and comments to support your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "26b6ef569dc2c8207c0e69cc984d80b9",
     "grade": true,
     "grade_id": "cell-a1305a62d8222591",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.4303, 1.3511, 1.1637, 0.7439, 1.0825, 0.3618, -0.123, -0.0832, -1.6435, 0.567])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_model_best.stages[1].coefficients # Returned coefficients from pipe_model_best\n",
    "\n",
    "# The two most important features for increasing rise time are motor_A (1.4303) and motor_B (1.3511) dummy variables\n",
    "# The two most important features for decreasing rise time are pgain (-1.6435) and screw_E (-0.123) dummy variable\n",
    "# I can make this statement because there is a direct relationship between feature weight and rise time\n",
    "# The more positive a weight is, the more that feature positively affects rise time\n",
    "# The more negative a weight is, the more that feature negatively affects rise time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
