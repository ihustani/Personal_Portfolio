{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported neccessary packages\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "config = {'CONSUMER_KEY' : 'o4VvwbAc7bkymkhm9vN8H55NW', 'CONSUMER_SECRET': 'foS7WfVRB6FaW12sLNeiLtixx6ztXgwDgu5wqW5XNvFCi1kAdT', 'OAUTH_TOKEN' : '1321150199729893378-tif0RaOjY7S897DtcTcUs2ZN2Uw6u0', 'OAUTH_SECRET' : 'ITpcls8zJgD6WQxYxwTQUpaZTUnhyXoQwRIN2dP8FM2eN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Twitter API access configuration\n",
    "auth = tweepy.OAuthHandler(config['CONSUMER_KEY'],config['CONSUMER_SECRET'])\n",
    "auth.set_access_token(config['OAUTH_TOKEN'],config['OAUTH_SECRET'])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined function for calling Twitter API, taking a specific hashtag as input and returning tweets as json object\n",
    "def tweet_search(hashtag):\n",
    "    query = hashtag\n",
    "    count = 1000\n",
    "    searched_tweets = [status for status in tweepy.Cursor(api.search, q=query).items(count)]\n",
    "\n",
    "    tweet_list = list(searched_tweets)\n",
    "    tweet_json = [tweet._json for tweet in tweet_list]\n",
    "    return tweet_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined function for converting json object to dataframe with specific column attributes\n",
    "def tweets_to_df(tweet_json):\n",
    "    ID = []\n",
    "    tweets = []\n",
    "    location = []\n",
    "    time = []\n",
    "\n",
    "    for tweet in tweet_json:\n",
    "        ID.append(tweet['id']) \n",
    "        tweets.append(tweet['text']) \n",
    "        location.append(tweet['user']['location'])\n",
    "        time.append(tweet['created_at'])\n",
    "\n",
    "    data_tuples = list(zip(ID, tweets,location,time))\n",
    "    tweets_df = pd.DataFrame(data_tuples, columns=['ID','tweets','location','time'])\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter A Hashtag Or Type 'QUIT': #maskup until:2020-11-16 since:2020-11-15\n",
      "Please Enter A Hashtag Or Type 'QUIT': QUIT\n"
     ]
    }
   ],
   "source": [
    "# Loop iterating through hashtag searches for the user\n",
    "while True:\n",
    "    hashtag = input(\"Please Enter A Hashtag Or Type 'QUIT': \")\n",
    "    if hashtag == 'QUIT':\n",
    "        break\n",
    "    Day = tweets_to_df(tweet_search(hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweets</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1328125627812114433</td>\n",
       "      <td>RT @ArTallks: GodSpeed üßë‚ÄçüöÄüßëüèª‚ÄçüöÄüßëüèæ‚ÄçüöÄüßëüèº‚ÄçüöÄ@SpaceX ...</td>\n",
       "      <td>Los Angeles Universe Omniverse</td>\n",
       "      <td>Sun Nov 15 23:59:59 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1328125567271538688</td>\n",
       "      <td>As if we needed evidence that the Pandemic is ...</td>\n",
       "      <td>#notinabubble</td>\n",
       "      <td>Sun Nov 15 23:59:45 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1328125516222754818</td>\n",
       "      <td>RT @nonsequiteuse: Hey @HiltonHouston &amp;amp; @H...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>Sun Nov 15 23:59:33 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1328125492545798144</td>\n",
       "      <td>RT @cartoonnetwork: Rep your fav #CartoonNetwo...</td>\n",
       "      <td>someone's mind</td>\n",
       "      <td>Sun Nov 15 23:59:27 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1328125490255835136</td>\n",
       "      <td>Waiting to take a pandemic seriously until you...</td>\n",
       "      <td>Norman, OK</td>\n",
       "      <td>Sun Nov 15 23:59:26 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1328063679926038531</td>\n",
       "      <td>RT @Alt_ReddTruq: #MaskUp</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>Sun Nov 15 19:53:50 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1328063582974734339</td>\n",
       "      <td>Do you think racist folks will finally get #BL...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>Sun Nov 15 19:53:27 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1328063420739031043</td>\n",
       "      <td>RT @cartoonnetwork: Rep your fav #CartoonNetwo...</td>\n",
       "      <td>Naahhhh, have a cawffee -w-</td>\n",
       "      <td>Sun Nov 15 19:52:48 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1328063393438322688</td>\n",
       "      <td>For those of you that need a reminder. #maskup...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Sun Nov 15 19:52:41 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1328063376891801600</td>\n",
       "      <td>RT @cartoonnetwork: Rep your fav #CartoonNetwo...</td>\n",
       "      <td></td>\n",
       "      <td>Sun Nov 15 19:52:37 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID                                             tweets  \\\n",
       "0    1328125627812114433  RT @ArTallks: GodSpeed üßë‚ÄçüöÄüßëüèª‚ÄçüöÄüßëüèæ‚ÄçüöÄüßëüèº‚ÄçüöÄ@SpaceX ...   \n",
       "1    1328125567271538688  As if we needed evidence that the Pandemic is ...   \n",
       "2    1328125516222754818  RT @nonsequiteuse: Hey @HiltonHouston &amp; @H...   \n",
       "3    1328125492545798144  RT @cartoonnetwork: Rep your fav #CartoonNetwo...   \n",
       "4    1328125490255835136  Waiting to take a pandemic seriously until you...   \n",
       "..                   ...                                                ...   \n",
       "995  1328063679926038531                          RT @Alt_ReddTruq: #MaskUp   \n",
       "996  1328063582974734339  Do you think racist folks will finally get #BL...   \n",
       "997  1328063420739031043  RT @cartoonnetwork: Rep your fav #CartoonNetwo...   \n",
       "998  1328063393438322688  For those of you that need a reminder. #maskup...   \n",
       "999  1328063376891801600  RT @cartoonnetwork: Rep your fav #CartoonNetwo...   \n",
       "\n",
       "                           location                            time  \n",
       "0    Los Angeles Universe Omniverse  Sun Nov 15 23:59:59 +0000 2020  \n",
       "1                     #notinabubble  Sun Nov 15 23:59:45 +0000 2020  \n",
       "2                    Houston, Texas  Sun Nov 15 23:59:33 +0000 2020  \n",
       "3                    someone's mind  Sun Nov 15 23:59:27 +0000 2020  \n",
       "4                        Norman, OK  Sun Nov 15 23:59:26 +0000 2020  \n",
       "..                              ...                             ...  \n",
       "995                    Florida, USA  Sun Nov 15 19:53:50 +0000 2020  \n",
       "996                      Texas, USA  Sun Nov 15 19:53:27 +0000 2020  \n",
       "997     Naahhhh, have a cawffee -w-  Sun Nov 15 19:52:48 +0000 2020  \n",
       "998                    New York, NY  Sun Nov 15 19:52:41 +0000 2020  \n",
       "999                                  Sun Nov 15 19:52:37 +0000 2020  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewed dataframe\n",
    "mask15 = Day\n",
    "mask15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataframe to csv file\n",
    "mask15.to_csv('C:\\\\Users\\\\ian_u\\\\OneDrive\\\\Documents\\\\IST 652\\\\mask15.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
